---
data: 2023.01.23
alias: [Алгоритм Штрассена и его оценка с помощью основного метода]
tags: math
symbol:
page: [[[]],0]
---
Его ключевая идея состоит в том, чтобы экономить на рекурсивном вызове по сравнению с более простым алгоритмом «разделяй и властвуй», что аналогично подходу, реализованному в умножении Карацубы. Экономия на рекурсивном вызове дает алгоритм с субкубическим временем исполнения.

Псевдоматрицы:
$$
X=\begin{pmatrix}
A & B \\
C & D
\end{pmatrix}
\text{ и } Y=\begin{pmatrix}
E & F \\
G & H
\end{pmatrix} \space \text{ (1)}$$
Матричные произведения:
$$
X \times Y = \begin{pmatrix}
A \times E + B \times G & A \times F + B \times H \\
C \times E + D \times G & C \times F + D \times H
\end{pmatrix} \space \text{ (2)}
$$

>[!Example] Pseudocode
>Вход: целочисленные матрицы размеров $n\times n$, X и Y.
>Выход: $Z=X\times Y$
>Допущение: $n$ является степенью числа 2
>
>if n = 1 then                                                                                                                  //базовый случай
>	return $1 \times 1$ - матрица с элементом $X[1][1] \times Y[1][1]$
>else 
>	$A,B,C,D$ := подматрицы $X$, как выше в (1)
>	$E,F,G,H$ := подматрицы $Y$, как выше в (1)
>	рекурсивно вычислить семь (предварительно отобранных) произведений
>	return соответствующие (предварительно отобранные) сложения и вычитания матриц, вычисленных на предыдущем шаге

Экономия времени на одном из восьми рекурсивных вызовов не просто уменьшает время работы алгоритма на 12,5 %. Рекурсивный вызов экономится снова и снова, так что экономия суммируется, это приводит к асимптотически превосходному времени исполнения.
### Детали реализации
Обозначим через $X$ и $Y$ две входные матрицы размером $n \times n$ и определим $A,\mathbf{B},\dots,H$. Приведем семь рекурсивных матричных умножений, выполняемых алгоритмом Штрассена:
$P_{1}=A \times (F-H)$
$P_{2}=(A+B)\times H$
$P_{3}=(C+D)\times E$
$P_{4}=D\times(G-E)$
$P_{5}=(A+D)\times(E+H)$
$P_{6}=(B-D)\times(G+H)$
$P_{7}=(A-C)\times(E+F)$
На вычисления P мы потратим $\Theta(n^{2})$ времени, чтобы доказать, что матричное умножения $X$ и $Y$ выполняется за $\Theta(n^{2})$ смотри уравнение ниже:
$$
X \times Y = \begin{pmatrix}
A \times E + B \times G & A \times F + B \times H \\
C \times E + D \times G & C \times F + D \times H
\end{pmatrix}=\begin{pmatrix}
P_{5}+P_{4}-P_{2}+P_{6} & P_{1}+P_{2} \\
P_{3}+P_{4} & P_{1}+P_{5}-P_{3}-P_{7}
\end{pmatrix}
$$
Чтобы удостоверитьс, что второе уравнение выполняется, проведем вычисления:
$P_{5}+P_{4}-P_{2}+P_{6}=(A+D)\times(E+H)+D\times(G-E)-(A+B)\times H+(B-D)\times(G+H)=$
$A\times E+A\times H+D\times E+D\times H+D\times G-D\times E-A\times H-B\times H+B\times G+B\times H -D\times G-D\times H =$
$A\times E+B\times G$

### Оценка с помощью основного метода
![[Основной метод#^0c9c61]] 
![[стандартное рекуррентное соотношение стратегии разделяй и влавствуй и теорема#^a655d5]]
$a$ = 7, $b$ = 2, $d$ = 2 случай 3
$7>2^{2}\to T(n)=O(n^{\log_{2}7})\approx O(n^{2.81})$
